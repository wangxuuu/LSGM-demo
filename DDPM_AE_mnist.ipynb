{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from utils import *\n",
    "from models.diffusion import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.ndimage import rotate\n",
    "from itertools import chain\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random seed\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# cuda = True if torch.cuda.is_available() else False\n",
    "# FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "# torch.set_default_tensor_type(FloatTensor)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sample_dir = './results/MNIST_DDPM'\n",
    "model_dir = './results/checkpoints/DDPM_MNIST'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the same shape torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "joint_training = True\n",
    "load_available = True\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "eps = 1e-6\n",
    "sigma_min = 0.001\n",
    "sigma_max = 10\n",
    "n_steps = 10\n",
    "annealed_step = 100\n",
    "\n",
    "num_steps = 100\n",
    "\n",
    "#制定每一步的beta\n",
    "betas = torch.linspace(-6,6,num_steps)\n",
    "betas = torch.sigmoid(betas)*(0.5e-2 - 1e-5)+1e-5\n",
    "\n",
    "#计算alpha、alpha_prod、alpha_prod_previous、alpha_bar_sqrt等变量的值\n",
    "alphas = 1-betas\n",
    "alphas_prod = torch.cumprod(alphas,0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(),alphas_prod[:-1]],0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "\n",
    "assert alphas.shape==alphas_prod.shape==alphas_prod_p.shape==\\\n",
    "alphas_bar_sqrt.shape==one_minus_alphas_bar_log.shape\\\n",
    "==one_minus_alphas_bar_sqrt.shape\n",
    "print(\"all the same shape\",betas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../Data/MNIST/',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(input_size=image_size, h_dim=h_dim, z_dim=z_dim, type='ce').to(device)\n",
    "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "# sn = SN_Model(device, n_steps, sigma_min, sigma_max, dim=z_dim, p = 0.3)\n",
    "sn = MLPDiffusion(num_steps)\n",
    "sn_optim = torch.optim.Adam(sn.parameters(), lr = 1e-3)\n",
    "joint_optim = torch.optim.Adam(params=chain(vae.parameters(), sn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100], Step [100/469], Reconst Loss: 21895.4082, KL Div: 1386.0198, Diffuse loss: 0.9691\n",
      "Epoch[1/100], Step [200/469], Reconst Loss: 17678.4805, KL Div: 1897.8455, Diffuse loss: 1.0043\n",
      "Epoch[1/100], Step [300/469], Reconst Loss: 16089.0830, KL Div: 2026.5127, Diffuse loss: 0.9869\n",
      "Epoch[1/100], Step [400/469], Reconst Loss: 15024.9023, KL Div: 2522.7236, Diffuse loss: 1.0276\n",
      "Epoch[2/100], Step [100/469], Reconst Loss: 13054.2422, KL Div: 2634.9219, Diffuse loss: 0.9988\n",
      "Epoch[2/100], Step [200/469], Reconst Loss: 13052.2402, KL Div: 2696.2197, Diffuse loss: 0.9633\n",
      "Epoch[2/100], Step [300/469], Reconst Loss: 12359.7207, KL Div: 2880.6323, Diffuse loss: 0.9779\n",
      "Epoch[2/100], Step [400/469], Reconst Loss: 12272.3213, KL Div: 2987.8767, Diffuse loss: 0.9717\n",
      "Epoch[3/100], Step [100/469], Reconst Loss: 12133.9316, KL Div: 2897.1218, Diffuse loss: 0.9678\n",
      "Epoch[3/100], Step [200/469], Reconst Loss: 11136.5479, KL Div: 2979.1045, Diffuse loss: 0.9626\n",
      "Epoch[3/100], Step [300/469], Reconst Loss: 11576.4492, KL Div: 3043.8257, Diffuse loss: 0.9918\n",
      "Epoch[3/100], Step [400/469], Reconst Loss: 11244.1074, KL Div: 3154.6399, Diffuse loss: 0.9475\n",
      "Epoch[4/100], Step [100/469], Reconst Loss: 11827.0039, KL Div: 3037.9058, Diffuse loss: 0.9812\n",
      "Epoch[4/100], Step [200/469], Reconst Loss: 10894.6211, KL Div: 2960.6765, Diffuse loss: 0.9770\n",
      "Epoch[4/100], Step [300/469], Reconst Loss: 10862.2305, KL Div: 3134.2495, Diffuse loss: 0.9515\n",
      "Epoch[4/100], Step [400/469], Reconst Loss: 10912.4033, KL Div: 3071.9707, Diffuse loss: 0.9578\n",
      "Epoch[5/100], Step [100/469], Reconst Loss: 10636.0742, KL Div: 3121.0691, Diffuse loss: 0.9758\n",
      "Epoch[5/100], Step [200/469], Reconst Loss: 11120.5645, KL Div: 3163.9294, Diffuse loss: 0.9563\n",
      "Epoch[5/100], Step [300/469], Reconst Loss: 10705.4619, KL Div: 3136.1196, Diffuse loss: 0.9817\n",
      "Epoch[5/100], Step [400/469], Reconst Loss: 10853.9834, KL Div: 3030.0388, Diffuse loss: 1.0113\n",
      "Epoch[6/100], Step [100/469], Reconst Loss: 10988.0645, KL Div: 3126.9475, Diffuse loss: 0.9824\n",
      "Epoch[6/100], Step [200/469], Reconst Loss: 10483.8613, KL Div: 3252.3320, Diffuse loss: 0.8987\n",
      "Epoch[6/100], Step [300/469], Reconst Loss: 10073.8809, KL Div: 3128.8955, Diffuse loss: 0.9202\n",
      "Epoch[6/100], Step [400/469], Reconst Loss: 10654.2217, KL Div: 3091.8269, Diffuse loss: 0.9370\n",
      "Epoch[7/100], Step [100/469], Reconst Loss: 10816.4268, KL Div: 3248.6299, Diffuse loss: 0.9538\n",
      "Epoch[7/100], Step [200/469], Reconst Loss: 11144.3701, KL Div: 3210.9851, Diffuse loss: 0.9218\n",
      "Epoch[7/100], Step [300/469], Reconst Loss: 10345.7539, KL Div: 3164.3101, Diffuse loss: 0.9698\n",
      "Epoch[7/100], Step [400/469], Reconst Loss: 10204.6924, KL Div: 3242.0151, Diffuse loss: 0.9683\n",
      "Epoch[8/100], Step [100/469], Reconst Loss: 10450.0713, KL Div: 3186.0220, Diffuse loss: 0.9527\n",
      "Epoch[8/100], Step [200/469], Reconst Loss: 10518.1113, KL Div: 3175.7788, Diffuse loss: 0.9445\n",
      "Epoch[8/100], Step [300/469], Reconst Loss: 10739.6641, KL Div: 3171.8740, Diffuse loss: 0.9288\n",
      "Epoch[8/100], Step [400/469], Reconst Loss: 10496.6904, KL Div: 3328.3289, Diffuse loss: 0.9320\n",
      "Epoch[9/100], Step [100/469], Reconst Loss: 10156.8682, KL Div: 3226.3455, Diffuse loss: 0.8810\n",
      "Epoch[9/100], Step [200/469], Reconst Loss: 10280.7871, KL Div: 3203.0674, Diffuse loss: 0.9526\n",
      "Epoch[9/100], Step [300/469], Reconst Loss: 10639.7090, KL Div: 3180.5996, Diffuse loss: 0.9486\n",
      "Epoch[9/100], Step [400/469], Reconst Loss: 10001.1768, KL Div: 3171.4443, Diffuse loss: 0.9090\n",
      "Epoch[10/100], Step [100/469], Reconst Loss: 10700.5078, KL Div: 3252.5779, Diffuse loss: 0.9583\n",
      "Epoch[10/100], Step [200/469], Reconst Loss: 10379.9551, KL Div: 3227.0513, Diffuse loss: 0.9360\n",
      "Epoch[10/100], Step [300/469], Reconst Loss: 10660.4521, KL Div: 3211.6689, Diffuse loss: 0.9766\n",
      "Epoch[10/100], Step [400/469], Reconst Loss: 9821.2334, KL Div: 3200.4507, Diffuse loss: 0.9210\n",
      "Epoch[11/100], Step [100/469], Reconst Loss: 10505.7734, KL Div: 3191.0066, Diffuse loss: 0.9224\n",
      "Epoch[11/100], Step [200/469], Reconst Loss: 10402.3428, KL Div: 3256.9729, Diffuse loss: 0.9318\n",
      "Epoch[11/100], Step [300/469], Reconst Loss: 10436.7832, KL Div: 3159.8572, Diffuse loss: 0.9290\n",
      "Epoch[11/100], Step [400/469], Reconst Loss: 10485.2744, KL Div: 3176.4661, Diffuse loss: 0.9219\n",
      "Epoch[12/100], Step [100/469], Reconst Loss: 9921.2188, KL Div: 3200.3115, Diffuse loss: 0.8998\n",
      "Epoch[12/100], Step [200/469], Reconst Loss: 10446.3457, KL Div: 3230.3232, Diffuse loss: 0.8826\n",
      "Epoch[12/100], Step [300/469], Reconst Loss: 10359.5566, KL Div: 3207.1599, Diffuse loss: 0.9231\n",
      "Epoch[12/100], Step [400/469], Reconst Loss: 10251.4883, KL Div: 3243.2119, Diffuse loss: 0.9022\n",
      "Epoch[13/100], Step [100/469], Reconst Loss: 10383.5088, KL Div: 3131.9561, Diffuse loss: 0.9676\n",
      "Epoch[13/100], Step [200/469], Reconst Loss: 10780.0039, KL Div: 3294.8945, Diffuse loss: 0.9420\n",
      "Epoch[13/100], Step [300/469], Reconst Loss: 10384.0391, KL Div: 3060.1072, Diffuse loss: 0.9603\n",
      "Epoch[13/100], Step [400/469], Reconst Loss: 10116.6582, KL Div: 3226.2395, Diffuse loss: 0.9566\n",
      "Epoch[14/100], Step [100/469], Reconst Loss: 10315.0596, KL Div: 3131.6877, Diffuse loss: 0.9376\n",
      "Epoch[14/100], Step [200/469], Reconst Loss: 10121.3145, KL Div: 3235.7759, Diffuse loss: 0.9251\n",
      "Epoch[14/100], Step [300/469], Reconst Loss: 10559.6807, KL Div: 3387.4067, Diffuse loss: 0.9491\n",
      "Epoch[14/100], Step [400/469], Reconst Loss: 10461.5820, KL Div: 3256.8335, Diffuse loss: 0.9429\n",
      "Epoch[15/100], Step [100/469], Reconst Loss: 9938.8184, KL Div: 3197.5413, Diffuse loss: 0.9257\n",
      "Epoch[15/100], Step [200/469], Reconst Loss: 10181.2852, KL Div: 3274.5671, Diffuse loss: 0.9159\n",
      "Epoch[15/100], Step [300/469], Reconst Loss: 10239.5352, KL Div: 3237.4084, Diffuse loss: 0.9129\n",
      "Epoch[15/100], Step [400/469], Reconst Loss: 9745.4043, KL Div: 3140.6636, Diffuse loss: 0.9674\n",
      "Epoch[16/100], Step [100/469], Reconst Loss: 9995.6748, KL Div: 3200.0376, Diffuse loss: 0.9575\n",
      "Epoch[16/100], Step [200/469], Reconst Loss: 9573.3613, KL Div: 3050.4756, Diffuse loss: 0.9427\n",
      "Epoch[16/100], Step [300/469], Reconst Loss: 10113.7861, KL Div: 3209.0833, Diffuse loss: 0.8879\n",
      "Epoch[16/100], Step [400/469], Reconst Loss: 9941.7686, KL Div: 3249.3574, Diffuse loss: 0.9630\n",
      "Epoch[17/100], Step [100/469], Reconst Loss: 10091.9541, KL Div: 3198.7678, Diffuse loss: 0.9114\n",
      "Epoch[17/100], Step [200/469], Reconst Loss: 9924.3477, KL Div: 3230.3999, Diffuse loss: 0.9564\n",
      "Epoch[17/100], Step [300/469], Reconst Loss: 10266.6543, KL Div: 3227.9851, Diffuse loss: 0.9602\n",
      "Epoch[17/100], Step [400/469], Reconst Loss: 10249.3604, KL Div: 3315.8643, Diffuse loss: 0.9639\n",
      "Epoch[18/100], Step [100/469], Reconst Loss: 10133.6123, KL Div: 3286.4409, Diffuse loss: 0.9271\n",
      "Epoch[18/100], Step [200/469], Reconst Loss: 10036.2910, KL Div: 3341.3862, Diffuse loss: 0.9546\n",
      "Epoch[18/100], Step [300/469], Reconst Loss: 10061.0957, KL Div: 3253.5525, Diffuse loss: 0.9173\n",
      "Epoch[18/100], Step [400/469], Reconst Loss: 10016.0820, KL Div: 3171.5090, Diffuse loss: 0.9524\n",
      "Epoch[19/100], Step [100/469], Reconst Loss: 9823.6270, KL Div: 3236.2791, Diffuse loss: 0.9805\n",
      "Epoch[19/100], Step [200/469], Reconst Loss: 10284.9443, KL Div: 3169.9062, Diffuse loss: 0.9502\n",
      "Epoch[19/100], Step [300/469], Reconst Loss: 10172.6406, KL Div: 3260.4214, Diffuse loss: 0.9084\n",
      "Epoch[19/100], Step [400/469], Reconst Loss: 9519.0332, KL Div: 3178.4590, Diffuse loss: 0.9355\n",
      "Epoch[20/100], Step [100/469], Reconst Loss: 9697.2715, KL Div: 3078.0540, Diffuse loss: 0.9457\n",
      "Epoch[20/100], Step [200/469], Reconst Loss: 10169.6738, KL Div: 3349.5007, Diffuse loss: 0.9273\n",
      "Epoch[20/100], Step [300/469], Reconst Loss: 10013.2617, KL Div: 3264.0166, Diffuse loss: 0.9075\n",
      "Epoch[20/100], Step [400/469], Reconst Loss: 10058.5615, KL Div: 3269.9131, Diffuse loss: 0.9689\n",
      "Epoch[21/100], Step [100/469], Reconst Loss: 9762.4424, KL Div: 3275.3525, Diffuse loss: 0.9426\n",
      "Epoch[21/100], Step [200/469], Reconst Loss: 10047.0117, KL Div: 3221.8735, Diffuse loss: 0.9400\n",
      "Epoch[21/100], Step [300/469], Reconst Loss: 10386.0820, KL Div: 3297.0991, Diffuse loss: 0.9177\n",
      "Epoch[21/100], Step [400/469], Reconst Loss: 9694.5840, KL Div: 3234.1934, Diffuse loss: 0.9034\n",
      "Epoch[22/100], Step [100/469], Reconst Loss: 9723.0713, KL Div: 3202.2695, Diffuse loss: 0.9425\n",
      "Epoch[22/100], Step [200/469], Reconst Loss: 10167.2979, KL Div: 3218.9832, Diffuse loss: 0.9285\n",
      "Epoch[22/100], Step [300/469], Reconst Loss: 10020.5488, KL Div: 3259.3647, Diffuse loss: 0.8995\n",
      "Epoch[22/100], Step [400/469], Reconst Loss: 9971.6436, KL Div: 3266.2061, Diffuse loss: 0.9417\n",
      "Epoch[23/100], Step [100/469], Reconst Loss: 9601.8271, KL Div: 3273.7339, Diffuse loss: 0.9228\n",
      "Epoch[23/100], Step [200/469], Reconst Loss: 10380.8965, KL Div: 3251.2261, Diffuse loss: 0.9613\n",
      "Epoch[23/100], Step [300/469], Reconst Loss: 9824.0928, KL Div: 3238.1599, Diffuse loss: 0.9411\n",
      "Epoch[23/100], Step [400/469], Reconst Loss: 9919.5938, KL Div: 3197.8328, Diffuse loss: 0.9259\n",
      "Epoch[24/100], Step [100/469], Reconst Loss: 10085.4844, KL Div: 3339.0708, Diffuse loss: 0.9309\n",
      "Epoch[24/100], Step [200/469], Reconst Loss: 10519.4834, KL Div: 3257.6890, Diffuse loss: 0.8978\n",
      "Epoch[24/100], Step [300/469], Reconst Loss: 9678.8301, KL Div: 3205.6597, Diffuse loss: 0.9181\n",
      "Epoch[24/100], Step [400/469], Reconst Loss: 10023.0664, KL Div: 3270.6787, Diffuse loss: 0.9087\n",
      "Epoch[25/100], Step [100/469], Reconst Loss: 9785.5312, KL Div: 3214.2397, Diffuse loss: 0.8706\n",
      "Epoch[25/100], Step [200/469], Reconst Loss: 9983.5605, KL Div: 3247.9583, Diffuse loss: 0.9148\n",
      "Epoch[25/100], Step [300/469], Reconst Loss: 10284.4229, KL Div: 3295.6001, Diffuse loss: 0.8976\n",
      "Epoch[25/100], Step [400/469], Reconst Loss: 9565.6914, KL Div: 3228.2390, Diffuse loss: 0.9394\n",
      "Epoch[26/100], Step [100/469], Reconst Loss: 10042.3789, KL Div: 3257.2041, Diffuse loss: 0.8962\n",
      "Epoch[26/100], Step [200/469], Reconst Loss: 9818.9531, KL Div: 3194.4453, Diffuse loss: 0.8692\n",
      "Epoch[26/100], Step [300/469], Reconst Loss: 10535.6074, KL Div: 3282.8804, Diffuse loss: 0.9517\n",
      "Epoch[26/100], Step [400/469], Reconst Loss: 10074.4844, KL Div: 3258.8628, Diffuse loss: 0.9292\n",
      "Epoch[27/100], Step [100/469], Reconst Loss: 10070.9189, KL Div: 3237.9587, Diffuse loss: 0.9206\n",
      "Epoch[27/100], Step [200/469], Reconst Loss: 10089.2676, KL Div: 3259.9351, Diffuse loss: 0.9116\n",
      "Epoch[27/100], Step [300/469], Reconst Loss: 10243.0508, KL Div: 3281.0068, Diffuse loss: 0.9011\n",
      "Epoch[27/100], Step [400/469], Reconst Loss: 9769.7559, KL Div: 3283.0464, Diffuse loss: 0.9458\n",
      "Epoch[28/100], Step [100/469], Reconst Loss: 10335.2500, KL Div: 3279.2451, Diffuse loss: 0.9441\n",
      "Epoch[28/100], Step [200/469], Reconst Loss: 10019.0820, KL Div: 3269.9111, Diffuse loss: 0.9093\n",
      "Epoch[28/100], Step [300/469], Reconst Loss: 10070.1572, KL Div: 3359.5667, Diffuse loss: 0.9617\n",
      "Epoch[28/100], Step [400/469], Reconst Loss: 9822.7910, KL Div: 3178.1047, Diffuse loss: 0.9275\n",
      "Epoch[29/100], Step [100/469], Reconst Loss: 9891.8398, KL Div: 3342.1079, Diffuse loss: 0.8929\n",
      "Epoch[29/100], Step [200/469], Reconst Loss: 10009.5762, KL Div: 3257.4111, Diffuse loss: 0.9078\n",
      "Epoch[29/100], Step [300/469], Reconst Loss: 9560.8184, KL Div: 3204.4126, Diffuse loss: 0.9109\n",
      "Epoch[29/100], Step [400/469], Reconst Loss: 10008.4795, KL Div: 3159.4229, Diffuse loss: 0.9354\n",
      "Epoch[30/100], Step [100/469], Reconst Loss: 9679.3662, KL Div: 3133.2812, Diffuse loss: 0.9285\n",
      "Epoch[30/100], Step [200/469], Reconst Loss: 9961.6914, KL Div: 3327.1099, Diffuse loss: 0.9712\n",
      "Epoch[30/100], Step [300/469], Reconst Loss: 9941.3193, KL Div: 3238.0532, Diffuse loss: 0.8974\n",
      "Epoch[30/100], Step [400/469], Reconst Loss: 10202.4766, KL Div: 3210.0598, Diffuse loss: 0.9039\n",
      "Epoch[31/100], Step [100/469], Reconst Loss: 9766.9258, KL Div: 3152.3079, Diffuse loss: 0.8878\n",
      "Epoch[31/100], Step [200/469], Reconst Loss: 10033.0713, KL Div: 3319.0110, Diffuse loss: 0.9441\n",
      "Epoch[31/100], Step [300/469], Reconst Loss: 10139.4404, KL Div: 3258.9563, Diffuse loss: 0.9408\n",
      "Epoch[31/100], Step [400/469], Reconst Loss: 9941.4355, KL Div: 3311.1851, Diffuse loss: 0.9399\n",
      "Epoch[32/100], Step [100/469], Reconst Loss: 10141.0840, KL Div: 3217.2620, Diffuse loss: 0.8971\n",
      "Epoch[32/100], Step [200/469], Reconst Loss: 10028.9424, KL Div: 3284.6218, Diffuse loss: 0.9330\n",
      "Epoch[32/100], Step [300/469], Reconst Loss: 9684.6348, KL Div: 3159.7473, Diffuse loss: 0.9173\n",
      "Epoch[32/100], Step [400/469], Reconst Loss: 9704.9873, KL Div: 3246.7905, Diffuse loss: 0.9486\n",
      "Epoch[33/100], Step [100/469], Reconst Loss: 10345.4824, KL Div: 3390.2632, Diffuse loss: 0.9451\n",
      "Epoch[33/100], Step [200/469], Reconst Loss: 9825.5332, KL Div: 3154.1865, Diffuse loss: 0.9553\n",
      "Epoch[33/100], Step [300/469], Reconst Loss: 9415.8965, KL Div: 3227.2273, Diffuse loss: 0.8825\n",
      "Epoch[33/100], Step [400/469], Reconst Loss: 9610.8877, KL Div: 3217.6406, Diffuse loss: 0.9278\n",
      "Epoch[34/100], Step [100/469], Reconst Loss: 9938.5107, KL Div: 3192.0540, Diffuse loss: 0.9303\n",
      "Epoch[34/100], Step [200/469], Reconst Loss: 9729.0732, KL Div: 3322.1565, Diffuse loss: 0.9281\n",
      "Epoch[34/100], Step [300/469], Reconst Loss: 9662.5234, KL Div: 3186.8528, Diffuse loss: 0.9377\n",
      "Epoch[34/100], Step [400/469], Reconst Loss: 9514.5703, KL Div: 3129.0618, Diffuse loss: 0.9216\n",
      "Epoch[35/100], Step [100/469], Reconst Loss: 10095.1426, KL Div: 3257.4622, Diffuse loss: 0.9080\n",
      "Epoch[35/100], Step [200/469], Reconst Loss: 9807.8652, KL Div: 3170.1387, Diffuse loss: 0.9378\n",
      "Epoch[35/100], Step [300/469], Reconst Loss: 9708.8516, KL Div: 3290.7698, Diffuse loss: 0.8926\n",
      "Epoch[35/100], Step [400/469], Reconst Loss: 10248.2393, KL Div: 3304.5750, Diffuse loss: 0.8578\n",
      "Epoch[36/100], Step [100/469], Reconst Loss: 9733.5859, KL Div: 3254.3154, Diffuse loss: 0.9159\n",
      "Epoch[36/100], Step [200/469], Reconst Loss: 9677.1943, KL Div: 3251.1323, Diffuse loss: 0.9416\n",
      "Epoch[36/100], Step [300/469], Reconst Loss: 9724.4951, KL Div: 3227.8132, Diffuse loss: 0.9368\n",
      "Epoch[36/100], Step [400/469], Reconst Loss: 9810.0684, KL Div: 3235.9419, Diffuse loss: 0.9156\n",
      "Epoch[37/100], Step [100/469], Reconst Loss: 9952.9668, KL Div: 3308.1008, Diffuse loss: 0.9290\n",
      "Epoch[37/100], Step [200/469], Reconst Loss: 9717.2988, KL Div: 3183.5354, Diffuse loss: 0.9007\n",
      "Epoch[37/100], Step [300/469], Reconst Loss: 10136.3555, KL Div: 3324.9534, Diffuse loss: 0.9214\n",
      "Epoch[37/100], Step [400/469], Reconst Loss: 10167.4053, KL Div: 3210.8064, Diffuse loss: 0.9455\n",
      "Epoch[38/100], Step [100/469], Reconst Loss: 10147.9395, KL Div: 3260.2297, Diffuse loss: 0.9389\n",
      "Epoch[38/100], Step [200/469], Reconst Loss: 9755.8516, KL Div: 3237.9087, Diffuse loss: 0.9098\n",
      "Epoch[38/100], Step [300/469], Reconst Loss: 9769.8359, KL Div: 3284.7573, Diffuse loss: 0.8974\n",
      "Epoch[38/100], Step [400/469], Reconst Loss: 9765.3242, KL Div: 3266.1707, Diffuse loss: 0.9685\n",
      "Epoch[39/100], Step [100/469], Reconst Loss: 10182.7773, KL Div: 3218.9922, Diffuse loss: 0.9355\n",
      "Epoch[39/100], Step [200/469], Reconst Loss: 10227.2168, KL Div: 3313.7659, Diffuse loss: 0.9026\n",
      "Epoch[39/100], Step [300/469], Reconst Loss: 9799.8145, KL Div: 3273.2681, Diffuse loss: 0.9256\n",
      "Epoch[39/100], Step [400/469], Reconst Loss: 9389.3154, KL Div: 3178.5769, Diffuse loss: 0.9557\n",
      "Epoch[40/100], Step [100/469], Reconst Loss: 9902.8506, KL Div: 3309.4966, Diffuse loss: 0.8741\n",
      "Epoch[40/100], Step [200/469], Reconst Loss: 9905.0879, KL Div: 3315.3660, Diffuse loss: 0.9303\n",
      "Epoch[40/100], Step [300/469], Reconst Loss: 10392.1309, KL Div: 3336.7432, Diffuse loss: 0.9279\n",
      "Epoch[40/100], Step [400/469], Reconst Loss: 10121.3760, KL Div: 3288.9729, Diffuse loss: 0.9061\n",
      "Epoch[41/100], Step [100/469], Reconst Loss: 9952.7852, KL Div: 3330.8477, Diffuse loss: 0.9223\n",
      "Epoch[41/100], Step [200/469], Reconst Loss: 9875.3984, KL Div: 3271.7229, Diffuse loss: 0.9135\n",
      "Epoch[41/100], Step [300/469], Reconst Loss: 10096.3770, KL Div: 3324.0686, Diffuse loss: 0.9137\n",
      "Epoch[41/100], Step [400/469], Reconst Loss: 9701.9932, KL Div: 3202.7695, Diffuse loss: 0.9081\n",
      "Epoch[42/100], Step [100/469], Reconst Loss: 9532.8750, KL Div: 3177.3337, Diffuse loss: 0.9294\n",
      "Epoch[42/100], Step [200/469], Reconst Loss: 10029.3838, KL Div: 3349.8000, Diffuse loss: 0.8901\n",
      "Epoch[42/100], Step [300/469], Reconst Loss: 10010.9707, KL Div: 3244.3174, Diffuse loss: 0.9426\n",
      "Epoch[42/100], Step [400/469], Reconst Loss: 10019.2783, KL Div: 3253.7832, Diffuse loss: 0.9181\n",
      "Epoch[43/100], Step [100/469], Reconst Loss: 9555.7266, KL Div: 3265.1301, Diffuse loss: 0.9235\n",
      "Epoch[43/100], Step [200/469], Reconst Loss: 9835.8779, KL Div: 3212.6440, Diffuse loss: 0.9786\n",
      "Epoch[43/100], Step [300/469], Reconst Loss: 9822.2607, KL Div: 3305.6792, Diffuse loss: 0.8755\n",
      "Epoch[43/100], Step [400/469], Reconst Loss: 10012.6182, KL Div: 3313.4617, Diffuse loss: 0.9265\n",
      "Epoch[44/100], Step [100/469], Reconst Loss: 10191.3320, KL Div: 3425.0562, Diffuse loss: 0.9444\n",
      "Epoch[44/100], Step [200/469], Reconst Loss: 9893.5439, KL Div: 3274.4602, Diffuse loss: 0.9320\n",
      "Epoch[44/100], Step [300/469], Reconst Loss: 9655.4395, KL Div: 3175.1440, Diffuse loss: 0.9120\n",
      "Epoch[44/100], Step [400/469], Reconst Loss: 10018.4922, KL Div: 3336.8242, Diffuse loss: 0.9078\n",
      "Epoch[45/100], Step [100/469], Reconst Loss: 9628.9805, KL Div: 3226.9199, Diffuse loss: 0.9219\n",
      "Epoch[45/100], Step [200/469], Reconst Loss: 10034.8984, KL Div: 3264.3530, Diffuse loss: 0.9201\n",
      "Epoch[45/100], Step [300/469], Reconst Loss: 9806.5000, KL Div: 3299.1204, Diffuse loss: 0.9057\n",
      "Epoch[45/100], Step [400/469], Reconst Loss: 9602.9785, KL Div: 3290.5544, Diffuse loss: 0.9209\n",
      "Epoch[46/100], Step [100/469], Reconst Loss: 10281.0645, KL Div: 3271.3308, Diffuse loss: 0.9081\n",
      "Epoch[46/100], Step [200/469], Reconst Loss: 9677.4629, KL Div: 3179.2981, Diffuse loss: 0.9389\n",
      "Epoch[46/100], Step [300/469], Reconst Loss: 9916.0947, KL Div: 3383.5068, Diffuse loss: 0.8914\n",
      "Epoch[46/100], Step [400/469], Reconst Loss: 9535.2988, KL Div: 3276.5823, Diffuse loss: 0.9228\n",
      "Epoch[47/100], Step [100/469], Reconst Loss: 9708.5791, KL Div: 3206.9304, Diffuse loss: 0.8968\n",
      "Epoch[47/100], Step [200/469], Reconst Loss: 9735.4268, KL Div: 3158.1592, Diffuse loss: 0.9280\n",
      "Epoch[47/100], Step [300/469], Reconst Loss: 9956.8057, KL Div: 3254.1731, Diffuse loss: 0.9272\n",
      "Epoch[47/100], Step [400/469], Reconst Loss: 9773.2637, KL Div: 3277.5112, Diffuse loss: 0.9196\n",
      "Epoch[48/100], Step [100/469], Reconst Loss: 9383.8086, KL Div: 3143.5254, Diffuse loss: 0.9112\n",
      "Epoch[48/100], Step [200/469], Reconst Loss: 9863.8955, KL Div: 3249.4417, Diffuse loss: 0.8932\n",
      "Epoch[48/100], Step [300/469], Reconst Loss: 10112.0283, KL Div: 3276.3394, Diffuse loss: 0.9159\n",
      "Epoch[48/100], Step [400/469], Reconst Loss: 10161.7559, KL Div: 3275.2126, Diffuse loss: 0.9205\n",
      "Epoch[49/100], Step [100/469], Reconst Loss: 9526.2920, KL Div: 3186.8364, Diffuse loss: 0.9506\n",
      "Epoch[49/100], Step [200/469], Reconst Loss: 9839.9766, KL Div: 3266.3271, Diffuse loss: 0.9181\n",
      "Epoch[49/100], Step [300/469], Reconst Loss: 9740.6309, KL Div: 3247.5896, Diffuse loss: 0.9165\n",
      "Epoch[49/100], Step [400/469], Reconst Loss: 9535.4893, KL Div: 3167.1650, Diffuse loss: 0.9037\n",
      "Epoch[50/100], Step [100/469], Reconst Loss: 9769.8164, KL Div: 3280.8579, Diffuse loss: 0.9169\n",
      "Epoch[50/100], Step [200/469], Reconst Loss: 9486.6074, KL Div: 3163.9478, Diffuse loss: 0.9175\n",
      "Epoch[50/100], Step [300/469], Reconst Loss: 9843.1670, KL Div: 3258.1602, Diffuse loss: 0.8927\n",
      "Epoch[50/100], Step [400/469], Reconst Loss: 10169.5410, KL Div: 3339.4673, Diffuse loss: 0.9066\n",
      "Epoch[51/100], Step [100/469], Reconst Loss: 10041.4951, KL Div: 3287.8381, Diffuse loss: 0.9234\n",
      "Epoch[51/100], Step [200/469], Reconst Loss: 9795.7578, KL Div: 3193.1201, Diffuse loss: 0.9000\n",
      "Epoch[51/100], Step [300/469], Reconst Loss: 9650.8887, KL Div: 3214.4204, Diffuse loss: 0.9148\n",
      "Epoch[51/100], Step [400/469], Reconst Loss: 9631.4434, KL Div: 3216.6409, Diffuse loss: 0.9226\n",
      "Epoch[52/100], Step [100/469], Reconst Loss: 9780.5449, KL Div: 3286.2754, Diffuse loss: 0.8737\n",
      "Epoch[52/100], Step [200/469], Reconst Loss: 9765.2480, KL Div: 3227.3557, Diffuse loss: 0.9209\n",
      "Epoch[52/100], Step [300/469], Reconst Loss: 9330.9707, KL Div: 3152.9829, Diffuse loss: 0.9282\n",
      "Epoch[52/100], Step [400/469], Reconst Loss: 9692.6748, KL Div: 3239.3657, Diffuse loss: 0.9133\n",
      "Epoch[53/100], Step [100/469], Reconst Loss: 9996.6250, KL Div: 3220.0969, Diffuse loss: 0.9159\n",
      "Epoch[53/100], Step [200/469], Reconst Loss: 10082.0684, KL Div: 3314.3281, Diffuse loss: 0.9169\n",
      "Epoch[53/100], Step [300/469], Reconst Loss: 10301.0479, KL Div: 3369.6755, Diffuse loss: 0.9532\n",
      "Epoch[53/100], Step [400/469], Reconst Loss: 9694.5635, KL Div: 3160.1980, Diffuse loss: 0.9148\n",
      "Epoch[54/100], Step [100/469], Reconst Loss: 9879.3633, KL Div: 3318.3169, Diffuse loss: 0.9089\n",
      "Epoch[54/100], Step [200/469], Reconst Loss: 10027.0938, KL Div: 3230.3518, Diffuse loss: 0.8962\n",
      "Epoch[54/100], Step [300/469], Reconst Loss: 9621.6699, KL Div: 3180.4419, Diffuse loss: 0.9442\n",
      "Epoch[54/100], Step [400/469], Reconst Loss: 10024.9141, KL Div: 3208.0947, Diffuse loss: 0.9192\n",
      "Epoch[55/100], Step [100/469], Reconst Loss: 9577.8721, KL Div: 3252.3755, Diffuse loss: 0.9410\n",
      "Epoch[55/100], Step [200/469], Reconst Loss: 9944.1270, KL Div: 3307.5815, Diffuse loss: 0.9052\n",
      "Epoch[55/100], Step [300/469], Reconst Loss: 9832.9277, KL Div: 3273.1138, Diffuse loss: 0.9175\n",
      "Epoch[55/100], Step [400/469], Reconst Loss: 9819.5459, KL Div: 3256.2056, Diffuse loss: 0.9211\n",
      "Epoch[56/100], Step [100/469], Reconst Loss: 9684.4639, KL Div: 3241.1140, Diffuse loss: 1.0119\n",
      "Epoch[56/100], Step [200/469], Reconst Loss: 9588.1621, KL Div: 3256.3289, Diffuse loss: 0.9174\n",
      "Epoch[56/100], Step [300/469], Reconst Loss: 9722.5791, KL Div: 3227.3101, Diffuse loss: 0.8834\n",
      "Epoch[56/100], Step [400/469], Reconst Loss: 9436.6201, KL Div: 3242.3491, Diffuse loss: 0.8845\n",
      "Epoch[57/100], Step [100/469], Reconst Loss: 9834.3965, KL Div: 3232.6489, Diffuse loss: 0.9140\n",
      "Epoch[57/100], Step [200/469], Reconst Loss: 9630.3516, KL Div: 3294.1111, Diffuse loss: 0.9605\n",
      "Epoch[57/100], Step [300/469], Reconst Loss: 9669.2529, KL Div: 3229.4651, Diffuse loss: 0.9070\n",
      "Epoch[57/100], Step [400/469], Reconst Loss: 10279.2617, KL Div: 3384.3535, Diffuse loss: 0.9156\n",
      "Epoch[58/100], Step [100/469], Reconst Loss: 9561.5254, KL Div: 3208.3789, Diffuse loss: 0.9180\n",
      "Epoch[58/100], Step [200/469], Reconst Loss: 9479.8936, KL Div: 3159.0017, Diffuse loss: 0.8774\n",
      "Epoch[58/100], Step [300/469], Reconst Loss: 9966.2676, KL Div: 3227.8167, Diffuse loss: 0.9179\n",
      "Epoch[58/100], Step [400/469], Reconst Loss: 9636.9951, KL Div: 3304.8892, Diffuse loss: 0.9392\n",
      "Epoch[59/100], Step [100/469], Reconst Loss: 9693.8301, KL Div: 3288.2913, Diffuse loss: 0.9270\n",
      "Epoch[59/100], Step [200/469], Reconst Loss: 9596.0449, KL Div: 3299.4697, Diffuse loss: 0.8990\n",
      "Epoch[59/100], Step [300/469], Reconst Loss: 9333.4287, KL Div: 3215.2654, Diffuse loss: 0.9038\n",
      "Epoch[59/100], Step [400/469], Reconst Loss: 9565.4209, KL Div: 3209.4155, Diffuse loss: 0.9105\n",
      "Epoch[60/100], Step [100/469], Reconst Loss: 9659.7793, KL Div: 3220.4763, Diffuse loss: 0.9629\n",
      "Epoch[60/100], Step [200/469], Reconst Loss: 9504.6270, KL Div: 3089.2163, Diffuse loss: 0.9006\n",
      "Epoch[60/100], Step [300/469], Reconst Loss: 9746.5352, KL Div: 3333.4170, Diffuse loss: 0.9521\n",
      "Epoch[60/100], Step [400/469], Reconst Loss: 9337.7695, KL Div: 3113.8730, Diffuse loss: 0.9572\n",
      "Epoch[61/100], Step [100/469], Reconst Loss: 9842.1348, KL Div: 3326.4629, Diffuse loss: 0.8900\n",
      "Epoch[61/100], Step [200/469], Reconst Loss: 9383.9297, KL Div: 3062.2812, Diffuse loss: 0.9305\n",
      "Epoch[61/100], Step [300/469], Reconst Loss: 9803.1553, KL Div: 3225.1016, Diffuse loss: 0.9294\n",
      "Epoch[61/100], Step [400/469], Reconst Loss: 9134.1016, KL Div: 3196.7756, Diffuse loss: 0.8786\n",
      "Epoch[62/100], Step [100/469], Reconst Loss: 9818.7051, KL Div: 3294.2002, Diffuse loss: 0.9385\n",
      "Epoch[62/100], Step [200/469], Reconst Loss: 9815.8867, KL Div: 3195.4536, Diffuse loss: 0.9583\n",
      "Epoch[62/100], Step [300/469], Reconst Loss: 9271.1240, KL Div: 3226.3428, Diffuse loss: 0.8935\n",
      "Epoch[62/100], Step [400/469], Reconst Loss: 9357.6699, KL Div: 3104.3884, Diffuse loss: 0.9256\n",
      "Epoch[63/100], Step [100/469], Reconst Loss: 9949.1895, KL Div: 3261.8401, Diffuse loss: 0.9125\n",
      "Epoch[63/100], Step [200/469], Reconst Loss: 9157.8496, KL Div: 3175.7461, Diffuse loss: 0.9044\n",
      "Epoch[63/100], Step [300/469], Reconst Loss: 9685.0352, KL Div: 3263.8071, Diffuse loss: 0.9226\n",
      "Epoch[63/100], Step [400/469], Reconst Loss: 9145.5723, KL Div: 3105.0164, Diffuse loss: 0.9290\n",
      "Epoch[64/100], Step [100/469], Reconst Loss: 9811.4131, KL Div: 3239.5195, Diffuse loss: 0.9445\n",
      "Epoch[64/100], Step [200/469], Reconst Loss: 9559.7383, KL Div: 3195.7268, Diffuse loss: 0.9133\n",
      "Epoch[64/100], Step [300/469], Reconst Loss: 9702.1025, KL Div: 3206.9556, Diffuse loss: 0.8900\n",
      "Epoch[64/100], Step [400/469], Reconst Loss: 9992.0244, KL Div: 3233.7166, Diffuse loss: 0.9007\n",
      "Epoch[65/100], Step [100/469], Reconst Loss: 9775.7100, KL Div: 3100.7942, Diffuse loss: 0.9304\n",
      "Epoch[65/100], Step [200/469], Reconst Loss: 9789.5215, KL Div: 3322.4053, Diffuse loss: 0.9393\n",
      "Epoch[65/100], Step [300/469], Reconst Loss: 9506.6211, KL Div: 3216.8096, Diffuse loss: 0.9536\n",
      "Epoch[65/100], Step [400/469], Reconst Loss: 9689.2158, KL Div: 3177.4839, Diffuse loss: 0.9220\n",
      "Epoch[66/100], Step [100/469], Reconst Loss: 9637.8906, KL Div: 3225.1257, Diffuse loss: 0.9261\n",
      "Epoch[66/100], Step [200/469], Reconst Loss: 9469.6318, KL Div: 3238.3640, Diffuse loss: 0.8936\n",
      "Epoch[66/100], Step [300/469], Reconst Loss: 10182.5684, KL Div: 3255.1689, Diffuse loss: 0.8706\n",
      "Epoch[66/100], Step [400/469], Reconst Loss: 9641.9355, KL Div: 3151.1882, Diffuse loss: 0.8740\n",
      "Epoch[67/100], Step [100/469], Reconst Loss: 10071.4131, KL Div: 3233.1162, Diffuse loss: 0.9538\n",
      "Epoch[67/100], Step [200/469], Reconst Loss: 9637.3350, KL Div: 3235.0366, Diffuse loss: 0.8754\n",
      "Epoch[67/100], Step [300/469], Reconst Loss: 9801.8691, KL Div: 3235.4497, Diffuse loss: 0.9275\n",
      "Epoch[67/100], Step [400/469], Reconst Loss: 9555.3398, KL Div: 3200.8411, Diffuse loss: 0.9429\n",
      "Epoch[68/100], Step [100/469], Reconst Loss: 10046.0850, KL Div: 3328.6582, Diffuse loss: 0.8900\n",
      "Epoch[68/100], Step [200/469], Reconst Loss: 9418.8203, KL Div: 3206.3250, Diffuse loss: 0.8999\n",
      "Epoch[68/100], Step [300/469], Reconst Loss: 9581.5361, KL Div: 3124.5503, Diffuse loss: 0.9024\n",
      "Epoch[68/100], Step [400/469], Reconst Loss: 9605.6387, KL Div: 3229.2839, Diffuse loss: 0.9322\n",
      "Epoch[69/100], Step [100/469], Reconst Loss: 9831.5645, KL Div: 3259.7080, Diffuse loss: 0.9192\n",
      "Epoch[69/100], Step [200/469], Reconst Loss: 9785.5879, KL Div: 3228.5942, Diffuse loss: 0.9124\n",
      "Epoch[69/100], Step [300/469], Reconst Loss: 9920.5781, KL Div: 3239.5620, Diffuse loss: 0.9132\n",
      "Epoch[69/100], Step [400/469], Reconst Loss: 9771.4805, KL Div: 3230.4263, Diffuse loss: 0.9246\n",
      "Epoch[70/100], Step [100/469], Reconst Loss: 9416.1182, KL Div: 3207.9727, Diffuse loss: 0.9070\n",
      "Epoch[70/100], Step [200/469], Reconst Loss: 10119.5693, KL Div: 3355.2637, Diffuse loss: 0.9663\n",
      "Epoch[70/100], Step [300/469], Reconst Loss: 9925.6631, KL Div: 3351.8770, Diffuse loss: 0.8941\n",
      "Epoch[70/100], Step [400/469], Reconst Loss: 9867.3691, KL Div: 3307.0728, Diffuse loss: 0.9308\n",
      "Epoch[71/100], Step [100/469], Reconst Loss: 9334.8369, KL Div: 3204.9739, Diffuse loss: 0.9147\n",
      "Epoch[71/100], Step [200/469], Reconst Loss: 10050.3164, KL Div: 3255.9187, Diffuse loss: 0.8961\n",
      "Epoch[71/100], Step [300/469], Reconst Loss: 9984.2637, KL Div: 3327.6074, Diffuse loss: 0.9432\n",
      "Epoch[71/100], Step [400/469], Reconst Loss: 9617.6797, KL Div: 3220.3789, Diffuse loss: 0.8862\n",
      "Epoch[72/100], Step [100/469], Reconst Loss: 9464.3877, KL Div: 3151.8899, Diffuse loss: 0.9040\n",
      "Epoch[72/100], Step [200/469], Reconst Loss: 9594.8535, KL Div: 3153.9211, Diffuse loss: 0.8991\n",
      "Epoch[72/100], Step [300/469], Reconst Loss: 9887.5156, KL Div: 3302.3701, Diffuse loss: 0.9318\n",
      "Epoch[72/100], Step [400/469], Reconst Loss: 9323.9336, KL Div: 3146.3103, Diffuse loss: 0.8976\n",
      "Epoch[73/100], Step [100/469], Reconst Loss: 9509.7285, KL Div: 3266.1929, Diffuse loss: 0.8812\n",
      "Epoch[73/100], Step [200/469], Reconst Loss: 9667.5615, KL Div: 3212.4614, Diffuse loss: 0.9330\n",
      "Epoch[73/100], Step [300/469], Reconst Loss: 9564.8857, KL Div: 3247.2151, Diffuse loss: 0.9180\n",
      "Epoch[73/100], Step [400/469], Reconst Loss: 9636.2793, KL Div: 3169.1348, Diffuse loss: 0.9485\n",
      "Epoch[74/100], Step [100/469], Reconst Loss: 9910.7393, KL Div: 3291.9089, Diffuse loss: 0.9386\n",
      "Epoch[74/100], Step [200/469], Reconst Loss: 9759.9473, KL Div: 3266.7932, Diffuse loss: 0.9013\n",
      "Epoch[74/100], Step [300/469], Reconst Loss: 9714.9473, KL Div: 3264.2515, Diffuse loss: 0.9368\n",
      "Epoch[74/100], Step [400/469], Reconst Loss: 9473.6680, KL Div: 3148.1455, Diffuse loss: 0.8881\n",
      "Epoch[75/100], Step [100/469], Reconst Loss: 9707.8301, KL Div: 3378.9878, Diffuse loss: 0.9027\n",
      "Epoch[75/100], Step [200/469], Reconst Loss: 9796.1553, KL Div: 3210.3870, Diffuse loss: 0.9195\n",
      "Epoch[75/100], Step [300/469], Reconst Loss: 9862.0879, KL Div: 3321.2344, Diffuse loss: 0.8846\n",
      "Epoch[75/100], Step [400/469], Reconst Loss: 9756.1826, KL Div: 3292.3730, Diffuse loss: 0.9268\n",
      "Epoch[76/100], Step [100/469], Reconst Loss: 9448.8945, KL Div: 3212.3557, Diffuse loss: 0.9166\n",
      "Epoch[76/100], Step [200/469], Reconst Loss: 10296.2832, KL Div: 3333.9189, Diffuse loss: 0.8964\n",
      "Epoch[76/100], Step [300/469], Reconst Loss: 9875.1289, KL Div: 3241.5754, Diffuse loss: 0.8810\n",
      "Epoch[76/100], Step [400/469], Reconst Loss: 9518.4004, KL Div: 3269.5249, Diffuse loss: 0.9168\n",
      "Epoch[77/100], Step [100/469], Reconst Loss: 9972.8623, KL Div: 3197.9077, Diffuse loss: 0.9012\n",
      "Epoch[77/100], Step [200/469], Reconst Loss: 9792.7578, KL Div: 3176.7573, Diffuse loss: 0.9212\n",
      "Epoch[77/100], Step [300/469], Reconst Loss: 9739.8564, KL Div: 3182.3625, Diffuse loss: 0.9176\n",
      "Epoch[77/100], Step [400/469], Reconst Loss: 9304.7939, KL Div: 3111.7471, Diffuse loss: 0.8966\n",
      "Epoch[78/100], Step [100/469], Reconst Loss: 9696.7178, KL Div: 3302.1965, Diffuse loss: 0.8697\n",
      "Epoch[78/100], Step [200/469], Reconst Loss: 9947.5732, KL Div: 3231.5664, Diffuse loss: 0.9283\n",
      "Epoch[78/100], Step [300/469], Reconst Loss: 9790.3027, KL Div: 3172.4443, Diffuse loss: 0.8801\n",
      "Epoch[78/100], Step [400/469], Reconst Loss: 9915.8594, KL Div: 3322.7407, Diffuse loss: 0.9461\n",
      "Epoch[79/100], Step [100/469], Reconst Loss: 10098.2275, KL Div: 3241.3762, Diffuse loss: 0.9515\n",
      "Epoch[79/100], Step [200/469], Reconst Loss: 9675.7725, KL Div: 3230.8557, Diffuse loss: 0.9528\n",
      "Epoch[79/100], Step [300/469], Reconst Loss: 9361.4033, KL Div: 3186.3438, Diffuse loss: 0.9462\n",
      "Epoch[79/100], Step [400/469], Reconst Loss: 9308.8135, KL Div: 3096.0415, Diffuse loss: 0.8690\n",
      "Epoch[80/100], Step [100/469], Reconst Loss: 9733.8994, KL Div: 3206.3394, Diffuse loss: 0.9202\n",
      "Epoch[80/100], Step [200/469], Reconst Loss: 9376.4912, KL Div: 3127.5083, Diffuse loss: 0.9324\n",
      "Epoch[80/100], Step [300/469], Reconst Loss: 9436.2881, KL Div: 3226.9922, Diffuse loss: 0.9019\n",
      "Epoch[80/100], Step [400/469], Reconst Loss: 9924.5205, KL Div: 3257.1367, Diffuse loss: 0.9031\n",
      "Epoch[81/100], Step [100/469], Reconst Loss: 9267.9141, KL Div: 3119.9119, Diffuse loss: 0.9427\n",
      "Epoch[81/100], Step [200/469], Reconst Loss: 9385.9219, KL Div: 3214.6421, Diffuse loss: 0.9237\n",
      "Epoch[81/100], Step [300/469], Reconst Loss: 9910.4121, KL Div: 3430.5464, Diffuse loss: 0.9212\n",
      "Epoch[81/100], Step [400/469], Reconst Loss: 9684.6807, KL Div: 3248.0718, Diffuse loss: 0.9399\n",
      "Epoch[82/100], Step [100/469], Reconst Loss: 9763.4844, KL Div: 3292.5547, Diffuse loss: 0.8268\n",
      "Epoch[82/100], Step [200/469], Reconst Loss: 9910.2686, KL Div: 3311.2637, Diffuse loss: 0.9118\n",
      "Epoch[82/100], Step [300/469], Reconst Loss: 9668.7695, KL Div: 3354.5410, Diffuse loss: 0.9427\n",
      "Epoch[82/100], Step [400/469], Reconst Loss: 9882.9570, KL Div: 3260.6987, Diffuse loss: 0.9614\n",
      "Epoch[83/100], Step [100/469], Reconst Loss: 9822.7500, KL Div: 3236.4675, Diffuse loss: 0.9510\n",
      "Epoch[83/100], Step [200/469], Reconst Loss: 9529.2344, KL Div: 3188.1289, Diffuse loss: 0.9610\n",
      "Epoch[83/100], Step [300/469], Reconst Loss: 9671.6084, KL Div: 3211.0762, Diffuse loss: 0.9209\n",
      "Epoch[83/100], Step [400/469], Reconst Loss: 10008.9717, KL Div: 3243.7461, Diffuse loss: 0.9208\n",
      "Epoch[84/100], Step [100/469], Reconst Loss: 9456.9424, KL Div: 3130.3792, Diffuse loss: 0.9393\n",
      "Epoch[84/100], Step [200/469], Reconst Loss: 9540.1426, KL Div: 3255.2239, Diffuse loss: 0.9413\n",
      "Epoch[84/100], Step [300/469], Reconst Loss: 9641.5010, KL Div: 3264.3408, Diffuse loss: 0.9237\n",
      "Epoch[84/100], Step [400/469], Reconst Loss: 9599.6484, KL Div: 3272.7146, Diffuse loss: 0.9456\n",
      "Epoch[85/100], Step [100/469], Reconst Loss: 9644.1973, KL Div: 3177.6687, Diffuse loss: 0.8698\n",
      "Epoch[85/100], Step [200/469], Reconst Loss: 9880.2383, KL Div: 3239.4158, Diffuse loss: 0.9554\n",
      "Epoch[85/100], Step [300/469], Reconst Loss: 9679.5820, KL Div: 3234.7451, Diffuse loss: 0.8911\n",
      "Epoch[85/100], Step [400/469], Reconst Loss: 9596.7744, KL Div: 3221.7815, Diffuse loss: 0.9095\n",
      "Epoch[86/100], Step [100/469], Reconst Loss: 9634.1133, KL Div: 3169.5474, Diffuse loss: 0.9169\n",
      "Epoch[86/100], Step [200/469], Reconst Loss: 9653.4766, KL Div: 3275.7734, Diffuse loss: 0.9461\n",
      "Epoch[86/100], Step [300/469], Reconst Loss: 9855.9219, KL Div: 3214.9250, Diffuse loss: 0.9179\n",
      "Epoch[86/100], Step [400/469], Reconst Loss: 9359.7480, KL Div: 3154.5359, Diffuse loss: 0.9241\n",
      "Epoch[87/100], Step [100/469], Reconst Loss: 9827.8066, KL Div: 3208.4614, Diffuse loss: 0.9117\n",
      "Epoch[87/100], Step [200/469], Reconst Loss: 9925.4648, KL Div: 3299.1111, Diffuse loss: 0.8759\n",
      "Epoch[87/100], Step [300/469], Reconst Loss: 9736.2051, KL Div: 3270.7642, Diffuse loss: 0.9219\n",
      "Epoch[87/100], Step [400/469], Reconst Loss: 9668.6680, KL Div: 3227.4531, Diffuse loss: 0.8841\n",
      "Epoch[88/100], Step [100/469], Reconst Loss: 9357.7012, KL Div: 3209.0991, Diffuse loss: 0.8747\n",
      "Epoch[88/100], Step [200/469], Reconst Loss: 9605.4883, KL Div: 3230.6455, Diffuse loss: 0.9413\n",
      "Epoch[88/100], Step [300/469], Reconst Loss: 9547.8613, KL Div: 3140.6167, Diffuse loss: 0.8698\n",
      "Epoch[88/100], Step [400/469], Reconst Loss: 9726.6035, KL Div: 3304.5049, Diffuse loss: 0.9032\n",
      "Epoch[89/100], Step [100/469], Reconst Loss: 9714.7676, KL Div: 3240.5522, Diffuse loss: 0.9184\n",
      "Epoch[89/100], Step [200/469], Reconst Loss: 9378.8867, KL Div: 3157.6560, Diffuse loss: 0.9013\n",
      "Epoch[89/100], Step [300/469], Reconst Loss: 9799.4727, KL Div: 3304.4189, Diffuse loss: 0.9250\n",
      "Epoch[89/100], Step [400/469], Reconst Loss: 9647.2051, KL Div: 3283.7600, Diffuse loss: 0.8826\n",
      "Epoch[90/100], Step [100/469], Reconst Loss: 9674.8281, KL Div: 3261.5513, Diffuse loss: 0.9248\n",
      "Epoch[90/100], Step [200/469], Reconst Loss: 9325.1221, KL Div: 3147.6477, Diffuse loss: 0.9049\n",
      "Epoch[90/100], Step [300/469], Reconst Loss: 9458.2461, KL Div: 3136.8911, Diffuse loss: 0.9378\n",
      "Epoch[90/100], Step [400/469], Reconst Loss: 9748.9297, KL Div: 3277.6233, Diffuse loss: 0.8896\n",
      "Epoch[91/100], Step [100/469], Reconst Loss: 9721.4941, KL Div: 3245.9429, Diffuse loss: 0.9124\n",
      "Epoch[91/100], Step [200/469], Reconst Loss: 9870.2441, KL Div: 3168.6519, Diffuse loss: 0.9092\n",
      "Epoch[91/100], Step [300/469], Reconst Loss: 9626.6914, KL Div: 3234.3865, Diffuse loss: 0.8703\n",
      "Epoch[91/100], Step [400/469], Reconst Loss: 9676.8867, KL Div: 3246.0659, Diffuse loss: 0.9329\n",
      "Epoch[92/100], Step [100/469], Reconst Loss: 9399.4395, KL Div: 3191.4790, Diffuse loss: 0.9428\n",
      "Epoch[92/100], Step [200/469], Reconst Loss: 9678.4590, KL Div: 3186.9265, Diffuse loss: 0.9452\n",
      "Epoch[92/100], Step [300/469], Reconst Loss: 9468.9355, KL Div: 3209.9580, Diffuse loss: 0.8822\n",
      "Epoch[92/100], Step [400/469], Reconst Loss: 9622.1846, KL Div: 3180.0347, Diffuse loss: 0.8698\n",
      "Epoch[93/100], Step [100/469], Reconst Loss: 9721.7373, KL Div: 3096.7734, Diffuse loss: 0.8996\n",
      "Epoch[93/100], Step [200/469], Reconst Loss: 9874.4893, KL Div: 3147.9351, Diffuse loss: 0.9128\n",
      "Epoch[93/100], Step [300/469], Reconst Loss: 9650.1621, KL Div: 3260.0120, Diffuse loss: 0.9027\n",
      "Epoch[93/100], Step [400/469], Reconst Loss: 10221.7324, KL Div: 3237.1753, Diffuse loss: 0.9484\n",
      "Epoch[94/100], Step [100/469], Reconst Loss: 8872.4844, KL Div: 3075.9487, Diffuse loss: 0.9058\n",
      "Epoch[94/100], Step [200/469], Reconst Loss: 9794.3945, KL Div: 3228.4478, Diffuse loss: 0.8805\n",
      "Epoch[94/100], Step [300/469], Reconst Loss: 9719.0938, KL Div: 3244.9868, Diffuse loss: 0.9252\n",
      "Epoch[94/100], Step [400/469], Reconst Loss: 9952.0342, KL Div: 3251.0305, Diffuse loss: 0.9129\n",
      "Epoch[95/100], Step [100/469], Reconst Loss: 9951.9238, KL Div: 3287.4529, Diffuse loss: 0.8825\n",
      "Epoch[95/100], Step [200/469], Reconst Loss: 9310.1934, KL Div: 3154.7251, Diffuse loss: 0.9724\n",
      "Epoch[95/100], Step [300/469], Reconst Loss: 9683.0742, KL Div: 3199.7432, Diffuse loss: 0.9300\n",
      "Epoch[95/100], Step [400/469], Reconst Loss: 9769.2031, KL Div: 3242.9971, Diffuse loss: 0.9648\n",
      "Epoch[96/100], Step [100/469], Reconst Loss: 9142.4180, KL Div: 3077.6511, Diffuse loss: 0.9217\n",
      "Epoch[96/100], Step [200/469], Reconst Loss: 9479.6699, KL Div: 3256.4854, Diffuse loss: 0.9377\n",
      "Epoch[96/100], Step [300/469], Reconst Loss: 9644.5508, KL Div: 3164.6997, Diffuse loss: 0.9273\n",
      "Epoch[96/100], Step [400/469], Reconst Loss: 9523.9443, KL Div: 3211.7173, Diffuse loss: 0.9011\n",
      "Epoch[97/100], Step [100/469], Reconst Loss: 9584.3516, KL Div: 3257.5127, Diffuse loss: 0.9227\n",
      "Epoch[97/100], Step [200/469], Reconst Loss: 9578.8135, KL Div: 3280.6753, Diffuse loss: 0.8746\n",
      "Epoch[97/100], Step [300/469], Reconst Loss: 9223.1455, KL Div: 3172.7463, Diffuse loss: 0.8973\n",
      "Epoch[97/100], Step [400/469], Reconst Loss: 9617.9570, KL Div: 3189.2173, Diffuse loss: 0.9246\n",
      "Epoch[98/100], Step [100/469], Reconst Loss: 9698.1602, KL Div: 3255.0359, Diffuse loss: 0.9740\n",
      "Epoch[98/100], Step [200/469], Reconst Loss: 10151.2812, KL Div: 3317.4102, Diffuse loss: 0.9532\n",
      "Epoch[98/100], Step [300/469], Reconst Loss: 9461.0488, KL Div: 3190.1877, Diffuse loss: 0.9209\n",
      "Epoch[98/100], Step [400/469], Reconst Loss: 10023.4834, KL Div: 3217.7249, Diffuse loss: 0.8654\n",
      "Epoch[99/100], Step [100/469], Reconst Loss: 9042.1523, KL Div: 3061.3745, Diffuse loss: 0.8956\n",
      "Epoch[99/100], Step [200/469], Reconst Loss: 9375.2031, KL Div: 3212.8542, Diffuse loss: 0.9472\n",
      "Epoch[99/100], Step [300/469], Reconst Loss: 9984.8955, KL Div: 3302.4453, Diffuse loss: 0.9220\n",
      "Epoch[99/100], Step [400/469], Reconst Loss: 9635.5996, KL Div: 3304.6523, Diffuse loss: 0.9037\n",
      "Epoch[100/100], Step [100/469], Reconst Loss: 9315.4453, KL Div: 3165.4758, Diffuse loss: 0.8819\n",
      "Epoch[100/100], Step [200/469], Reconst Loss: 9564.1387, KL Div: 3159.7805, Diffuse loss: 0.9461\n",
      "Epoch[100/100], Step [300/469], Reconst Loss: 9435.0625, KL Div: 3164.0352, Diffuse loss: 0.9233\n",
      "Epoch[100/100], Step [400/469], Reconst Loss: 9491.8984, KL Div: 3191.4617, Diffuse loss: 0.9326\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        if joint_training:\n",
    "            mu, log_var = vae.encode(x)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "            x_reconst = vae.decode(z)\n",
    "            # Compute reconstruction loss and kl divergence\n",
    "            reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss_sn = diffusion_loss_fn(sn, z,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,num_steps)\n",
    "            loss = loss_sn + reconst_loss + kl_div\n",
    "\n",
    "            joint_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            joint_optim.step()\n",
    "        else:\n",
    "            #============= First Stage: Update VAE ==============#\n",
    "            # Forward pass\n",
    "            x_reconst, mu, log_var = vae(x)\n",
    "            # Compute reconstruction loss and kl divergence\n",
    "            # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "            reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            \n",
    "            # Backprop and optimize\n",
    "            vae_loss = reconst_loss + kl_div\n",
    "            vae_optimizer.zero_grad()\n",
    "            vae_loss.backward()\n",
    "            vae_optimizer.step()\n",
    "\n",
    "            #============= Second Stage: Update SN ==============#\n",
    "            mu, log_var = vae.encode(x)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "\n",
    "            loss_sn = sn.loss(z)\n",
    "            vae_optimizer.zero_grad()\n",
    "            sn_optim.zero_grad()\n",
    "            loss_sn.backward()\n",
    "            sn_optim.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}, Diffuse loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item(), loss_sn.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(x.shape[0], z_dim).to(device)\n",
    "        out = vae.decode(z).view(-1, 1, 28, 28)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = vae(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the diffused ima ges\n",
    "        # dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, sn, device, eps=eps)\n",
    "        # z_ = forward_proc(z, sigma_min, sigma_max, n_steps, device=device, only_final=True)\n",
    "        # sample = dynamic.sampling(x.shape[0], z_dim, sample=z_, only_final=True)\n",
    "\n",
    "        sample = ddim_sample(sn, num_steps=num_steps, batch_size=x.shape[0], dim=z_dim)\n",
    "        # sample = dynamic.sampling(x.shape[0], z_dim, only_final=True)\n",
    "        out = vae.decode(sample).view(-1, 1, 28, 28)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'diffuse-{}.png'.format(epoch+1)))\n",
    "torch.save({'sn_state':sn.state_dict(), 'vae_state':vae.state_dict()}, model_dir+'ckpt.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('xu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca77da5a2651d428d298ea3d77cb6cfe29dc494bcc518222eca7638029259bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
