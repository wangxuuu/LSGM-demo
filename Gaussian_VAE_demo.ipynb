{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDiffuse the latent space of VAE model to random noise;\\nApply to Gaussian samples as an example.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Diffuse the latent space of VAE model to random noise;\n",
    "Apply to Gaussian samples as an example.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random seed\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(FloatTensor)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dim = 6\n",
    "batch_size = 40\n",
    "sample_size = 400\n",
    "rho = 0.9\n",
    "num_epochs = 60\n",
    "learning_rate = 1e-3\n",
    "z_dim = 10\n",
    "sample_dir = './results/samples'\n",
    "lamd = 10\n",
    "\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "data = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = sample_size, to_cuda = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = torch.utils.data.DataLoader(GetLoader(data), batch_size=40, shuffle=True, drop_last=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/60], Step [400/400], Reconst Loss: 1.0642, KL Div: 8.1283\n",
      "Epoch[2/60], Step [400/400], Reconst Loss: 1.1130, KL Div: 3.4735\n",
      "Epoch[3/60], Step [400/400], Reconst Loss: 1.0169, KL Div: 2.0712\n",
      "Epoch[4/60], Step [400/400], Reconst Loss: 1.0126, KL Div: 1.5666\n",
      "Epoch[5/60], Step [400/400], Reconst Loss: 1.0015, KL Div: 1.3773\n",
      "Epoch[6/60], Step [400/400], Reconst Loss: 1.0152, KL Div: 1.1255\n",
      "Epoch[7/60], Step [400/400], Reconst Loss: 1.0145, KL Div: 1.0425\n",
      "Epoch[8/60], Step [400/400], Reconst Loss: 0.9926, KL Div: 0.8028\n",
      "Epoch[9/60], Step [400/400], Reconst Loss: 1.1073, KL Div: 0.7275\n",
      "Epoch[10/60], Step [400/400], Reconst Loss: 0.8231, KL Div: 0.5559\n",
      "Epoch[11/60], Step [400/400], Reconst Loss: 0.9632, KL Div: 0.5421\n",
      "Epoch[12/60], Step [400/400], Reconst Loss: 1.0235, KL Div: 0.5336\n",
      "Epoch[13/60], Step [400/400], Reconst Loss: 1.1165, KL Div: 0.4769\n",
      "Epoch[14/60], Step [400/400], Reconst Loss: 1.0707, KL Div: 0.4287\n",
      "Epoch[15/60], Step [400/400], Reconst Loss: 0.9353, KL Div: 0.4168\n",
      "Epoch[16/60], Step [400/400], Reconst Loss: 0.9728, KL Div: 0.3445\n",
      "Epoch[17/60], Step [400/400], Reconst Loss: 0.9780, KL Div: 0.3622\n",
      "Epoch[18/60], Step [400/400], Reconst Loss: 1.0261, KL Div: 0.3264\n",
      "Epoch[19/60], Step [400/400], Reconst Loss: 0.8779, KL Div: 0.3355\n",
      "Epoch[20/60], Step [400/400], Reconst Loss: 1.0641, KL Div: 0.2870\n",
      "Epoch[21/60], Step [400/400], Reconst Loss: 1.0404, KL Div: 0.3085\n",
      "Epoch[22/60], Step [400/400], Reconst Loss: 0.8845, KL Div: 0.2457\n",
      "Epoch[23/60], Step [400/400], Reconst Loss: 1.1147, KL Div: 0.2593\n",
      "Epoch[24/60], Step [400/400], Reconst Loss: 1.0395, KL Div: 0.2216\n",
      "Epoch[25/60], Step [400/400], Reconst Loss: 0.9355, KL Div: 0.2101\n",
      "Epoch[26/60], Step [400/400], Reconst Loss: 0.8986, KL Div: 0.2269\n",
      "Epoch[27/60], Step [400/400], Reconst Loss: 0.9137, KL Div: 0.2068\n",
      "Epoch[28/60], Step [400/400], Reconst Loss: 0.8953, KL Div: 0.1841\n",
      "Epoch[29/60], Step [400/400], Reconst Loss: 0.9193, KL Div: 0.1894\n",
      "Epoch[30/60], Step [400/400], Reconst Loss: 1.1006, KL Div: 0.1843\n",
      "Epoch[31/60], Step [400/400], Reconst Loss: 0.9279, KL Div: 0.1655\n",
      "Epoch[32/60], Step [400/400], Reconst Loss: 1.0744, KL Div: 0.1559\n",
      "Epoch[33/60], Step [400/400], Reconst Loss: 1.0244, KL Div: 0.1708\n",
      "Epoch[34/60], Step [400/400], Reconst Loss: 1.0597, KL Div: 0.1667\n",
      "Epoch[35/60], Step [400/400], Reconst Loss: 0.9724, KL Div: 0.1755\n",
      "Epoch[36/60], Step [400/400], Reconst Loss: 1.0319, KL Div: 0.1715\n",
      "Epoch[37/60], Step [400/400], Reconst Loss: 1.0249, KL Div: 0.1524\n",
      "Epoch[38/60], Step [400/400], Reconst Loss: 0.8730, KL Div: 0.1385\n",
      "Epoch[39/60], Step [400/400], Reconst Loss: 1.0402, KL Div: 0.1571\n",
      "Epoch[40/60], Step [400/400], Reconst Loss: 0.9864, KL Div: 0.1264\n",
      "Epoch[41/60], Step [400/400], Reconst Loss: 1.0502, KL Div: 0.1332\n",
      "Epoch[42/60], Step [400/400], Reconst Loss: 0.9331, KL Div: 0.1323\n",
      "Epoch[43/60], Step [400/400], Reconst Loss: 1.0115, KL Div: 0.1373\n",
      "Epoch[44/60], Step [400/400], Reconst Loss: 1.0025, KL Div: 0.1351\n",
      "Epoch[45/60], Step [400/400], Reconst Loss: 1.0687, KL Div: 0.1184\n",
      "Epoch[46/60], Step [400/400], Reconst Loss: 1.1162, KL Div: 0.1172\n",
      "Epoch[47/60], Step [400/400], Reconst Loss: 0.9667, KL Div: 0.0994\n",
      "Epoch[48/60], Step [400/400], Reconst Loss: 0.8886, KL Div: 0.1063\n",
      "Epoch[49/60], Step [400/400], Reconst Loss: 0.8266, KL Div: 0.1096\n",
      "Epoch[50/60], Step [400/400], Reconst Loss: 1.0635, KL Div: 0.1123\n",
      "Epoch[51/60], Step [400/400], Reconst Loss: 1.0025, KL Div: 0.0973\n",
      "Epoch[52/60], Step [400/400], Reconst Loss: 1.0122, KL Div: 0.0993\n",
      "Epoch[53/60], Step [400/400], Reconst Loss: 0.8777, KL Div: 0.0924\n",
      "Epoch[54/60], Step [400/400], Reconst Loss: 0.8960, KL Div: 0.0842\n",
      "Epoch[55/60], Step [400/400], Reconst Loss: 0.9416, KL Div: 0.0834\n",
      "Epoch[56/60], Step [400/400], Reconst Loss: 0.9233, KL Div: 0.0983\n",
      "Epoch[57/60], Step [400/400], Reconst Loss: 0.9560, KL Div: 0.0910\n",
      "Epoch[58/60], Step [400/400], Reconst Loss: 0.9065, KL Div: 0.0861\n",
      "Epoch[59/60], Step [400/400], Reconst Loss: 0.8813, KL Div: 0.0792\n",
      "Epoch[60/60], Step [400/400], Reconst Loss: 1.0430, KL Div: 0.0779\n"
     ]
    }
   ],
   "source": [
    "model = VAE(input_size=sample_dim*2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, x in enumerate(dataLoader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).to(torch.float32)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "\n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        # reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        reconst_loss = F.mse_loss(x_reconst, x)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss = lamd*reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, (i+1)*batch_size, len(data), reconst_loss.item(), kl_div.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z)\n",
    "        fig = plot_fig(out[:,:sample_dim].cpu(), out[:,sample_dim:].cpu(), d=6)\n",
    "        plt.savefig(os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        fig = plot_fig(out[:,:sample_dim].cpu(), out[:,sample_dim:].cpu(), d=6)\n",
    "        plt.savefig(os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))\n",
    "        plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52b3e5fe9304ee37ed6fc02b58fb2a8a470f895336a7b69fe331a7c2f400c80f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
