{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from utils import *\n",
    "from models.scorenetwork import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from itertools import chain\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random seed\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(FloatTensor)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sample_dir = './results/MNIST_DAE'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_training = True\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "eps = 1e-6\n",
    "sigma_min = 0.001\n",
    "sigma_max = 10\n",
    "n_steps = 10\n",
    "annealed_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../Data/MNIST/',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [100/469], Reconst Loss: 22262.2383, KL Div: 1389.5240, Diffuse loss: 1.0002\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 18096.0859, KL Div: 1948.9353, Diffuse loss: 0.9919\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15765.6279, KL Div: 2313.4150, Diffuse loss: 0.9061\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14814.1807, KL Div: 2550.2549, Diffuse loss: 0.9350\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13195.8281, KL Div: 2684.5554, Diffuse loss: 0.7573\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12802.8047, KL Div: 2912.6306, Diffuse loss: 0.7771\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12581.1191, KL Div: 2880.2310, Diffuse loss: 0.6526\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12251.8145, KL Div: 2997.8713, Diffuse loss: 0.7156\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11663.4277, KL Div: 3072.2434, Diffuse loss: 0.7507\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11646.7480, KL Div: 3059.5444, Diffuse loss: 0.7011\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11290.7441, KL Div: 2988.0974, Diffuse loss: 0.7722\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11374.5732, KL Div: 3143.1370, Diffuse loss: 0.7401\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 10918.3721, KL Div: 3144.4580, Diffuse loss: 0.7610\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 10682.7891, KL Div: 3168.3062, Diffuse loss: 0.7701\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11495.4180, KL Div: 3225.4209, Diffuse loss: 0.7675\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 10681.0234, KL Div: 3167.6885, Diffuse loss: 0.8492\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 11210.0059, KL Div: 3271.1965, Diffuse loss: 0.7451\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10384.4297, KL Div: 3122.2163, Diffuse loss: 0.7911\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10820.8398, KL Div: 3162.6484, Diffuse loss: 0.6966\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10775.7900, KL Div: 3229.8716, Diffuse loss: 0.6633\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10876.3047, KL Div: 3153.9385, Diffuse loss: 0.7954\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10572.3330, KL Div: 3138.1306, Diffuse loss: 0.6305\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10944.2510, KL Div: 3284.3123, Diffuse loss: 0.7270\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10986.6914, KL Div: 3246.5569, Diffuse loss: 0.7871\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10799.9727, KL Div: 3295.1260, Diffuse loss: 0.6654\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10641.1660, KL Div: 3163.8040, Diffuse loss: 0.7462\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10669.7295, KL Div: 3274.2617, Diffuse loss: 0.7703\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10595.5156, KL Div: 3184.0483, Diffuse loss: 0.7509\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10404.8955, KL Div: 3229.0054, Diffuse loss: 0.7258\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10900.4121, KL Div: 3222.9531, Diffuse loss: 0.6821\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10398.6953, KL Div: 3178.0803, Diffuse loss: 0.7603\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10358.3223, KL Div: 3237.0803, Diffuse loss: 0.7320\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10591.1279, KL Div: 3245.2412, Diffuse loss: 0.7004\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 9955.6924, KL Div: 3131.5059, Diffuse loss: 0.7317\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10085.1211, KL Div: 3265.8218, Diffuse loss: 0.7197\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10820.4932, KL Div: 3291.1423, Diffuse loss: 0.7817\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 9987.8604, KL Div: 3209.5796, Diffuse loss: 0.7229\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10580.1592, KL Div: 3288.6821, Diffuse loss: 0.7398\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10483.6846, KL Div: 3255.3145, Diffuse loss: 0.7414\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10080.5049, KL Div: 3179.1489, Diffuse loss: 0.7250\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10153.1484, KL Div: 3150.9524, Diffuse loss: 0.7188\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10410.1514, KL Div: 3221.4302, Diffuse loss: 0.7508\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 9972.2998, KL Div: 3245.6162, Diffuse loss: 0.7867\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10027.6582, KL Div: 3215.1902, Diffuse loss: 0.7077\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 11118.0518, KL Div: 3243.8711, Diffuse loss: 0.7130\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10570.0410, KL Div: 3327.8232, Diffuse loss: 0.7533\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10454.4355, KL Div: 3308.0569, Diffuse loss: 0.7235\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10463.6807, KL Div: 3259.6138, Diffuse loss: 0.6294\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10198.2510, KL Div: 3289.1890, Diffuse loss: 0.7333\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10437.2285, KL Div: 3197.2119, Diffuse loss: 0.7234\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10391.8516, KL Div: 3284.0220, Diffuse loss: 0.7980\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10242.2354, KL Div: 3238.0415, Diffuse loss: 0.7808\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10181.3027, KL Div: 3325.7773, Diffuse loss: 0.7808\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10247.1934, KL Div: 3284.7891, Diffuse loss: 0.7243\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10188.1670, KL Div: 3176.6658, Diffuse loss: 0.7119\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10622.2168, KL Div: 3279.2119, Diffuse loss: 0.7604\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10163.4648, KL Div: 3172.2720, Diffuse loss: 0.7983\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10301.5146, KL Div: 3157.2832, Diffuse loss: 0.7736\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10328.5605, KL Div: 3199.5718, Diffuse loss: 0.7398\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10189.5518, KL Div: 3230.4707, Diffuse loss: 0.8074\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(input_size=image_size, h_dim=h_dim, z_dim=z_dim, type='ce').to(device)\n",
    "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "sn = SN_Model(device, n_steps, sigma_min, sigma_max, dim=z_dim, p = 0.3)\n",
    "sn_optim = torch.optim.Adam(sn.parameters(), lr = 0.005)\n",
    "dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, sn, device, eps=eps)\n",
    "\n",
    "joint_optim = torch.optim.Adam(params=chain(vae.parameters(), sn.parameters()))\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        if joint_training:\n",
    "            mu, log_var = vae.encode(x)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "            x_reconst = vae.decode(z)\n",
    "            # Compute reconstruction loss and kl divergence\n",
    "            reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss_sn = sn.loss_fn(z)\n",
    "            loss = loss_sn + reconst_loss + kl_div\n",
    "\n",
    "            joint_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            joint_optim.step()\n",
    "        else:\n",
    "            #============= First Stage: Update VAE ==============#\n",
    "            # Forward pass\n",
    "            x_reconst, mu, log_var = vae(x)\n",
    "            # Compute reconstruction loss and kl divergence\n",
    "            # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "            reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "            # Backprop and optimize\n",
    "            vae_loss = reconst_loss + kl_div\n",
    "            vae_optimizer.zero_grad()\n",
    "            vae_loss.backward()\n",
    "            vae_optimizer.step()\n",
    "\n",
    "            #============= Second Stage: Update SN ==============#\n",
    "            mu, log_var = vae.encode(x)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "\n",
    "            loss_sn = sn.loss_fn(z)\n",
    "            vae_optimizer.zero_grad()\n",
    "            sn_optim.zero_grad()\n",
    "            loss_sn.backward()\n",
    "            sn_optim.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}, Diffuse loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item(), loss_sn.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(x.shape[0], z_dim).to(device)\n",
    "        out = vae.decode(z).view(-1, 1, 28, 28)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = vae(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the diffused ima ges\n",
    "        dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, sn, device, eps=eps)\n",
    "        sample = dynamic.sampling(x.shape[0], z_dim, only_final=True)\n",
    "        out = vae.decode(sample).view(-1, 1, 28, 28)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'diffuse-{}.png'.format(epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ani_imshow(sample, sampling_number = 64):\n",
    "\n",
    "    row_number = int(math.sqrt(sampling_number))\n",
    "    col_number = int(math.sqrt(sampling_number))\n",
    "    sample = sample[:sampling_number].detach().cpu().numpy()\n",
    "    shape = sample.shape\n",
    "    show_sample = np.zeros([row_number * shape[2], col_number * shape[3] ]).astype(np.float32)\n",
    "    for row in range(row_number):\n",
    "        for col in range(col_number):\n",
    "            sample_ = sample[row + col * row_number][0]\n",
    "            show_sample[ row * shape[2] : (row+1) * shape[2], col * shape[3] : (col+1) * shape[3] ] = (sample_ - sample_.min()) / (sample_.max() - sample_.min()) * 255\n",
    "\n",
    "    show_sample = show_sample.astype(np.uint8)\n",
    "\n",
    "    return show_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnnealedLangevinDynamic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_582319/3074448655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdynamic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnnealedLangevinDynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannealed_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdiffuse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AnnealedLangevinDynamic' is not defined"
     ]
    }
   ],
   "source": [
    "only_final = False\n",
    "n_steps = 8\n",
    "test_size = 36\n",
    "dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, sn, device, eps=eps)\n",
    "sample = dynamic.sampling(test_size, z_dim, only_final)\n",
    "diffuse_data = vae.decode(sample)\n",
    "\n",
    "step_size = sample.size(0)\n",
    "fig, axs = plt.subplots(1, step_size, figsize=(step_size * 6, 6), constrained_layout = True)\n",
    "for i in range(step_size):\n",
    "    diff_data = diffuse_data[i].view(-1, 1, 28, 28)\n",
    "    axs[i].imshow(ani_imshow(diff_data, sampling_number = test_size), animated=True, cmap = 'gray')\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52b3e5fe9304ee37ed6fc02b58fb2a8a470f895336a7b69fe331a7c2f400c80f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
